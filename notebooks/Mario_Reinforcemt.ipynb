{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necassary Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You need to download the following packages:\n",
    "- `pip install gym-super-mario-bros==7.3.0`\n",
    "- `pip install nes-py==8.2.1`\n",
    "- `pip install gym==0.21.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_MOVEMENT # This is the list of possible actions that our character can take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Our Mario Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "actions_before_wrapping = env.action_space # This is the number of possible actions that our character can take berfore wrapping\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing Number of actions before and after the wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that JoypadSpace wrapper reduces the action space from 256 discrete values to 7 discrete values which will make our model train faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of actions before wrapping: \", actions_before_wrapping)\n",
    "print(\"Number of actions after wrapping: \", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This means that the game screen will be of size 240 x 256 x 3 (RGB) and the action space will be of size 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation space: \", env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the possible actions that we can take are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Action List: \", SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "for step in range(5): # remember to change this to 1000000\n",
    "    if done:\n",
    "        # starts the game or resets it if it is over\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample()) # random action\n",
    "    env.render() # render the game to the screen\n",
    "env.close() # closes the game window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the reward system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actions:\n",
    "    - `env.action_space.sample()` returns a random action\n",
    "\n",
    "    - `env.action_space.n` returns the number of actions\n",
    "\n",
    "    - Since we have 7 actions, we can take any action from 0 to 6 & thus the `env.action_space.sample()` returns number from 0 to 6\n",
    "- Step:\n",
    "    `env.step(action)` \n",
    "    \n",
    "    - The step function takes in an action and returns the next state, the reward for that action, whether the game is over or not and some additional information\n",
    "\n",
    "    - Examples to clarify how step works:\n",
    "\n",
    "    - `env.step(1)[0]` returns the next state\n",
    "\n",
    "    - `env.step(1)[1]` returns the reward\n",
    "\n",
    "    - `env.step(1)[2]` returns whether the game is over or not\n",
    "    \n",
    "    - `env.step(1)[3]` returns information after taking a specific action\n",
    "- Reset:\n",
    "    - `env.reset()` resets the environment and returns the initial state\n",
    "- Info:\n",
    "    - `env.step(1)[3]` returns information after taking a specific action\n",
    "    - it returns a dictionary, the below table will illustrate the keys and their values:\n",
    "\n",
    "        | Key | Type | Description |\n",
    "        | --- | --- | --- |\n",
    "        | coins | int | Number of coins collected |\n",
    "        | flag_get | bool | True if the level was completed |\n",
    "        | life | int | Remaining lives |\n",
    "        | score | int | Current score |\n",
    "        | stage | int | Current stage |\n",
    "        | status | str | Level status |\n",
    "        | time | int | Remaining time |\n",
    "        | world | int | Current world |\n",
    "        | x_pos | int | Mario's x position |\n",
    "        | y_pos | int | Mario's y position |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking samples of the state, reward, done and info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)[0] # returns the state of the game after taking action 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)[1] # returns the reward after taking action 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)[2] # returns the done boolean after taking action 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(1)[3] # returns the info after taking action 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing The Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import for preprocessing\n",
    "- You need to install the following:\n",
    "    - PyTorch either CPU or GPU version\n",
    "    - Stable Baselines 3:\n",
    "        \n",
    "        -  `pip install stable-baselines3==1.6.0`\n",
    "\n",
    "- `from gym.wrappers import FrameStack, GrayScaleObservation`:\n",
    "    \n",
    "    - `GrayScaleObservation` is used to convert the RGB image to grayscale image\n",
    "\n",
    "\n",
    "\n",
    "- `from stable_baselines.common.vec_env import VecFrameStack, DummyVecEnv`:\n",
    "    \n",
    "    - `VecFrameStack` make the environment vectorized and stacks the frames together\n",
    "        \n",
    "    - `DummyVecEnv` is used to make the environment vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GrayScale the environment\n",
    "env = GrayScaleObservation(env,keep_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_grayscale = env.reset()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(initial_state)\n",
    "plt.title(\"RGB Observation\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(initial_state_grayscale)\n",
    "plt.title(\"Grayscale Observation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of initial state: \", initial_state.shape)\n",
    "print(\"Shape of grayscale state: \", initial_state_grayscale.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Gray Scale in the Dummy Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap inside a DummyVecEnv to support vectorized environments\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_grayscale_wrapped = env.reset()\n",
    "# compare the shapes\n",
    "print(\"Shape of initial state: \", initial_state.shape)\n",
    "print(\"Shape of initial state grayscale: \", initial_state_grayscale.shape)\n",
    "print(\"Shape of initial state grayscale wrapped: \", initial_state_grayscale_wrapped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VecFrameStack(env,n_stack=4, channels_order=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_grayscale_wrapped_stacked = env.reset()\n",
    "# compare the shapes\n",
    "print(\"Shape of initial state: \", initial_state.shape)\n",
    "print(\"Shape of initial state grayscale: \", initial_state_grayscale.shape)\n",
    "print(\"Shape of initial state grayscale wrapped: \", initial_state_grayscale_wrapped.shape)\n",
    "print(\"Shape of initial state grayscale wrapped stacked: \", initial_state_grayscale_wrapped_stacked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualizing_Frames(initial_state, initial_state_grayscale, initial_state_grayscale_wrapped, initial_state_grayscale_wrapped_stacked):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(initial_state)\n",
    "    plt.title(\"RGB Observation\")\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(initial_state_grayscale)\n",
    "    plt.title(\"Grayscale Observation\")\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(initial_state_grayscale_wrapped[0])\n",
    "    plt.title(\"GrayScale Wrapped\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(initial_state_grayscale_wrapped_stacked[0])\n",
    "    plt.title(\"GrayScale Wrapped Stacked\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualizing_Frames(initial_state, initial_state_grayscale, initial_state_grayscale_wrapped, initial_state_grayscale_wrapped_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note -> The state changes each time we take an action or a step thats why the stacked frames are different & have different viusal information as we applied steps only on the vectorized stacked frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each step we take the stacked frames change & thus we will have new state\n",
    "for i in range(3):\n",
    "    initial_state_grayscale_wrapped_stacked,_,__,___ = env.step([env.action_space.sample()])\n",
    "    # Visualizing all frames \n",
    "    Visualizing_Frames(initial_state, initial_state_grayscale, initial_state_grayscale_wrapped, initial_state_grayscale_wrapped_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO # load PPO (Proximal Policy Optimization) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"../train/new_model_4200000.zip\", env=env)\n",
    "# 3500000 passed level 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "# loop through the game\n",
    "while True:\n",
    "    action, _= model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
